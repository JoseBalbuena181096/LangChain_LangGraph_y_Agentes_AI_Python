## Componentes clave

Los principales componentes clave de lanchaing, son 
- Chain: Secuencia de llamadas a componentes, como modelos de lenguaje, herramientas externas y otras cadenas.
- Runnable: Objeto que puede ser invocado para ejecutar una secuencia de llamadas a componentes. Recibe una serie de entradas y produce una serie de salidas.

Langchaing nos permite unir diferentes runnables en una secuencia, para formar una cadena de llamadas.


## Tarea: Mini-Proyecto: AnÃ¡lisis de sentimientos con LangChain
ğŸ“‹ Objetivo

En esta tarea construirÃ¡s desde cero un sistema completo de anÃ¡lisis de sentimientos usando LangChain. AprenderÃ¡s a crear funciones personalizadas, convertirlas en objetos Runnable usando RunnableLambda, y combinarlas en cadenas de procesamiento complejas.

âš ï¸ Importante: Esta tarea introduce conceptos avanzados de LangChain y es completamente normal que encuentres dificultades. No te preocupes si no puedes completar todos los puntos, el objetivo principal es que practiques el uso de RunnableLambda y entiendas cÃ³mo encadenar operaciones. La soluciÃ³n completa estarÃ¡ disponible en la siguiente clase para consulta. Â¡Experimenta, aprende del proceso y diviÃ©rtete construyendo!



ğŸ¯ Lo que aprenderÃ¡s

RunnableLambda: Convertir funciones Python en objetos Runnable

Cadenas complejas: Combinar mÃºltiples operaciones de procesamiento

Manejo de JSON: Estructurar respuestas del modelo

Preprocesamiento: Limpiar y preparar texto para anÃ¡lisis

Arquitectura modular: Dividir problemas complejos en pasos simples



ğŸ—ï¸ Arquitectura del Sistema

Tu sistema final tendrÃ¡ esta estructura:

Texto de entrada â†’ Preprocesamiento â†’ AnÃ¡lisis Completo â†’ Resultado
                                           â†™        â†˜
                                    Resumen    Sentimiento


ğŸ› ï¸ ImplementaciÃ³n Paso a Paso

1. ConfiguraciÃ³n Inicial

Empezemos con las importaciones y configuraciÃ³n bÃ¡sica:

from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
import json
 
# ConfiguraciÃ³n del modelo
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)


Pregunta reflexiva: Â¿Por quÃ© usamos temperature=0 para anÃ¡lisis de sentimientos?



2. Preprocesador de Texto

Objetivo: Crear una funciÃ³n que limpie y prepare el texto.

Tu turno: Implementa la funciÃ³n de preprocesamiento:

def preprocess_text(text):
    """Limpia el texto eliminando espacios extras y limitando longitud"""
    # Pista: usa .strip() para eliminar espacios
    # Pista: limita a 500 caracteres con slicing [:500]
    return # Â¡Completa aquÃ­!
 
# Convertir la funciÃ³n en un Runnable
preprocessor = RunnableLambda(preprocess_text)


3. Generador de ResÃºmenes

Objetivo: Crear una funciÃ³n que genere un resumen conciso del texto.

def generate_summary(text):
    """Genera un resumen conciso del texto"""
    prompt = f"Resume en una sola oraciÃ³n: {text}"
    response = llm.invoke(prompt)
    return response.content


Reto: Â¿PodrÃ­as mejorar este prompt para obtener mejores resÃºmenes?



4. Analizador de Sentimientos

Objetivo: Crear una funciÃ³n que analice el sentimiento y devuelva JSON estructurado.

def analyze_sentiment(text):
    """Analiza el sentimiento y devuelve resultado estructurado"""
    prompt = f"""Analiza el sentimiento del siguiente texto.
    Responde ÃšNICAMENTE en formato JSON vÃ¡lido:
    {{"sentimiento": "positivo|negativo|neutro", "razon": "justificaciÃ³n breve"}}
    
    Texto: {text}"""
    
    response = llm.invoke(prompt)
    try:
        return json.loads(response.content)
    except json.JSONDecodeError:
        return {"sentimiento": "neutro", "razon": "Error en anÃ¡lisis"}


Pregunta: Â¿Por quÃ© es importante el manejo de errores con try/except aquÃ­?



5. FunciÃ³n de CombinaciÃ³n

Objetivo: Unificar los resultados de resumen y anÃ¡lisis de sentimientos.

def merge_results(data):
    """Combina los resultados de ambas ramas en un formato unificado"""
    return {
        "resumen": data["resumen"],
        "sentimiento": data["sentimiento_data"]["sentimiento"],
        "razon": data["sentimiento_data"]["razon"]
    }


6. FunciÃ³n de Procesamiento Principal

Objetivo: Coodinar el anÃ¡lisis completo (resumen + sentimientos).

def process_one(t):
    resumen = generate_summary(t)              # Llamada 1 al LLM
    sentimiento_data = analyze_sentiment(t)    # Llamada 2 al LLM
    return merge_results({
        "resumen": resumen,
        "sentimiento_data": sentimiento_data
    })
 
# Convertir en Runnable
process = RunnableLambda(process_one)


7. ConstrucciÃ³n de la Cadena Final

Objetivo: Conectar todos los componentes usando LCEL.

# La cadena completa
chain = preprocessor | process


Â¡Eso es todo! Tu sistema estÃ¡ listo para usar.



8. Probando tu Sistema

# Prueba con diferentes textos
textos_prueba = [
    "Â¡Me encanta este producto! Funciona perfectamente y llegÃ³ muy rÃ¡pido.",
    "El servicio al cliente fue terrible, nadie me ayudÃ³ con mi problema.",
    "El clima estÃ¡ nublado hoy, probablemente llueva mÃ¡s tarde."
]
 
for texto in textos_prueba:
    resultado = chain.invoke(texto)
    print(f"Texto: {texto}")
    print(f"Resultado: {resultado}")
    print("-" * 50)


ğŸ’­ Reflexiones Finales

Â¿QuÃ© ventajas tiene dividir el procesamiento en funciones separadas?

Â¿CÃ³mo mejorarÃ­as la precisiÃ³n del anÃ¡lisis de sentimientos?

Â¿QuÃ© otros de anÃ¡lisis podrÃ­as aÃ±adir a este sistema?

Â¿CÃ³mo manejarÃ­as textos en diferentes idiomas?



Â¡Recuerda: el objetivo es aprender y experimentar. No te presiones para completar todo perfectamente! ğŸš€

