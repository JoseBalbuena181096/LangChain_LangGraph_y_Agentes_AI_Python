# âš–ï¸ Sistema RAG â€“ Asistente Legal (Contratos de Arrendamiento)

Asistente legal especializado en contratos de arrendamiento que usa RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG). Combina tÃ©cnicas de recuperaciÃ³n MMR con generaciÃ³n de mÃºltiples consultas (MultiQuery) y un enfoque hÃ­brido mediante Ensemble para encontrar los fragmentos mÃ¡s relevantes de tus contratos y responder con precisiÃ³n.

## ğŸ“¦ QuÃ© incluye
- Interfaz en `Streamlit` para chat y visualizaciÃ³n de fragmentos relevantes.
- Pipeline RAG en `LangChain` con `Chroma` como vector store.
- RecuperaciÃ³n hÃ­brida: `MMR + Similarity` con `EnsembleRetriever`.
- Prompts personalizados para consulta mÃºltiple y respuesta legal estructurada.

## ğŸ—‚ï¸ Estructura del proyecto
```
./asistente_legal_RAG/
â”œâ”€â”€ app.py               # UI en Streamlit
â”œâ”€â”€ rag_system.py        # Pipeline RAG y retrievers
â”œâ”€â”€ config.py            # ParÃ¡metros de modelos, bÃºsqueda y almacenamiento
â”œâ”€â”€ prompts.py           # Plantillas de prompts
â””â”€â”€ contratos/           # PDFs con contratos de arrendamiento
```

## ğŸ”§ Arquitectura y flujo
1. Usuario escribe una consulta en la UI (`app.py`).
2. El sistema inicializa el RAG y el retriever (`rag_system.initialize_rag_system`).
3. `MultiQueryRetriever` genera 3 variaciones de la consulta usando `llm_queries`.
4. Se consulta el vector store `Chroma` con `MMR` para diversidad y relevancia.
5. Si `ENABLE_HYBRID_SEARCH=True`, se combina `MMR` + `similarity` con `EnsembleRetriever` (pesos configurables).
6. Se formatea el contexto (`format_docs`) y se pasa al `PromptTemplate` (`RAG_TEMPLATE`).
7. `llm_generation` produce la respuesta final que se muestra en el chat.
8. En el panel derecho se enumeran los fragmentos de documentos usados: fuente, pÃ¡gina y contenido.

## âš™ï¸ ConfiguraciÃ³n principal (`config.py`)
- `EMBEDDING_MODEL`: modelo de embeddings (`text-embedding-3-large`).
- `QUERY_MODEL`: LLM para generar variaciones de consulta.
- `GENERATION_MODEL`: LLM para generar respuestas finales.
- `CHROMA_DB_PATH`: directorio persistente del vector store.
- `SEARCH_TYPE`: `mmr` por defecto.
- `MMR_DIVERSITY_LAMBDA`: equilibrio relevancia/diversidad (0â€“1).
- `MMR_FETCH_K`: candidatos para MMR.
- `SEARCH_K`: nÃºmero de documentos finales.
- `ENABLE_HYBRID_SEARCH`: activa el `EnsembleRetriever`.
- `SIMILARITY_THRESHOLD`: umbral de similitud para el ensemble.

Nota: La UI muestra nombres ilustrativos de modelos. Los modelos efectivos se definen en `config.py`.

## ğŸ§© Prompts (`prompts.py`)
- `RAG_TEMPLATE`: encuadre legal, cita cuando sea relevante y estructura la respuesta.
- `MULTI_QUERY_PROMPT`: guÃ­a para generar 3 variaciones Ãºtiles de la consulta.
- `RELEVANCE_PROMPT` y `ENTITY_EXTRACTION_PROMPT`: disponibles para futuras extensiones.

## âœ… Requisitos
- Python 3.10+
- OpenAI API Key vÃ¡lida
- Dependencias:
  - `streamlit`, `python-dotenv`
  - `langchain`, `langchain-openai`, `langchain-community`
  - `chromadb`

Instala dependencias:

```bash
pip install streamlit python-dotenv langchain langchain-openai langchain-community chromadb
```

## ğŸ”‘ Variables de entorno
Este proyecto carga variables desde `.env` (vÃ­a `dotenv`). AsegÃºrate de definir:

```bash
OPENAI_API_KEY="tu_api_key"
```

Puedes ubicar el `.env` en el directorio raÃ­z donde ejecutas `streamlit run app.py`.

## ğŸ§± Preparar la base vectorial (Chroma)
Si es la primera vez o no existe `CHROMA_DB_PATH`, crea la base vectorial a partir de los PDFs de `contratos/` con este script de ejemplo:

```python
# ingest.py
import os
from glob import glob
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

CHROMA_DB_PATH = "/home/jose/Ingenieria_de_LLM/LangChain_LangGraph_y_Agentes_AI_Python/3_RAG_y_LangChain/chroma_db"
CONTRACTS_DIR = "./contratos"

# Cargar PDFs
docs = []
for pdf_path in glob(os.path.join(CONTRACTS_DIR, "*.pdf")):
    loader = PyPDFLoader(pdf_path)
    docs.extend(loader.load())

# Partir en fragmentos
splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=150)
chunks = splitter.split_documents(docs)

# Crear y persistir vector store
emb = OpenAIEmbeddings(model="text-embedding-3-large")
Chroma.from_documents(chunks, embedding=emb, persist_directory=CHROMA_DB_PATH)
print(f"Persistido en: {CHROMA_DB_PATH}")
```

Ejecuta:

```bash
python ingest.py
```

## ğŸš€ EjecuciÃ³n
Desde la carpeta `asistente_legal_RAG`:

```bash
streamlit run app.py
```

- Escribe tu consulta en el chat: ejemplo â€œÂ¿QuiÃ©n es el arrendatario en el contrato de vivienda 1?â€
- A la derecha verÃ¡s los fragmentos relevantes con fuente y pÃ¡gina.

## ğŸ” RecuperaciÃ³n y parÃ¡metros
- `MMR` equilibra diversidad y relevancia: ajusta `MMR_DIVERSITY_LAMBDA`.
- `SEARCH_K` define cuÃ¡ntos documentos finales se pasan al LLM.
- `MultiQueryRetriever` usa `QUERY_MODEL` para reformular la consulta 3 veces.
- `EnsembleRetriever` combina `MMR` y `similarity` con `weights=[0.7, 0.3]` y `SIMILARITY_THRESHOLD`.

## ğŸ› ï¸ PersonalizaciÃ³n rÃ¡pida
- Cambia modelos en `config.py` segÃºn tu disponibilidad.
- Desactiva el hÃ­brido: `ENABLE_HYBRID_SEARCH = False`.
- Aumenta `SEARCH_K` para respuestas mÃ¡s contextualizadas.
- Eleva `MMR_FETCH_K` si tienes mÃ¡s documentos y quieres mayor diversidad.

## ğŸ§ª Ejemplos de consulta
- â€œÂ¿CuÃ¡l es la duraciÃ³n del contrato de arrendamiento de vivienda 2?â€
- â€œImporte mensual del alquiler y forma de pago del local de negocio.â€
- â€œDirecciÃ³n de la propiedad en la plaza de garaje.â€

## ğŸ©º Troubleshooting
- â€œNo se encuentra `OPENAI_API_KEY`â€ â†’ crea `.env` con tu clave o exporta en entorno.
- â€œRuta `CHROMA_DB_PATH` no existeâ€ â†’ ejecuta `ingest.py` o corrige la ruta en `config.py`.
- â€œRespuestas vacÃ­as o poco relevantesâ€ â†’ incrementa `SEARCH_K` y/o ajusta `MMR_DIVERSITY_LAMBDA`.
- â€œModelos no disponiblesâ€ â†’ reemplaza por modelos compatibles en `config.py`.

## ğŸ”’ Nota legal
Este asistente no sustituye asesorÃ­a legal profesional. Ãšsalo como apoyo para lectura y anÃ¡lisis de contratos.

## ğŸ“ CrÃ©ditos
- [LangChain](https://python.langchain.com/)
- [ChromaDB](https://www.trychroma.com/)
- OpenAI API