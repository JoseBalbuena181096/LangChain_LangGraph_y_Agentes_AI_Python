# üîß CustomMultiQueryRetriever - Documentaci√≥n T√©cnica

## üìã Contexto

### Problema Original
En **LangChain 1.0+**, el m√≥dulo `langchain.retrievers.multi_query` fue eliminado o movido, causando:

```python
ModuleNotFoundError: No module named 'langchain.retrievers.multi_query'
```

### Soluci√≥n Implementada
Creaci√≥n de `CustomMultiQueryRetriever` - una implementaci√≥n personalizada que replica la funcionalidad del `MultiQueryRetriever` original.

---

## üéØ ¬øQu√© es MultiQueryRetriever?

Es un retriever que **mejora la calidad de b√∫squeda** generando m√∫ltiples variaciones de una consulta y combinando los resultados.

### Ejemplo Visual

```
Consulta Original:
"¬øC√≥mo reseteo mi contrase√±a?"

       ‚Üì MultiQueryRetriever ‚Üì

Genera 3-4 variaciones:
1. "¬øC√≥mo reseteo mi contrase√±a?"
2. "Recuperar contrase√±a olvidada"  
3. "Restablecer password de cuenta"
4. "Cambiar clave de acceso"

       ‚Üì B√∫squeda en ChromaDB ‚Üì

Documentos encontrados (sin duplicados):
- Manual Usuario (Secci√≥n Contrase√±as)
- FAQ (Pregunta #12)
- Gu√≠a Troubleshooting (Problema #3)

       ‚Üì Resultado Final ‚Üì

Respuesta con 3 fuentes, Confianza: 0.85
```

---

## üîç Ventajas sobre B√∫squeda Simple

| Aspecto | B√∫squeda Simple | MultiQuery |
|---------|-----------------|------------|
| **Precisi√≥n** | Depende de palabras exactas | Busca sin√≥nimos y variaciones |
| **Recall** | Puede perder documentos relevantes | Mayor cobertura |
| **Robustez** | Sensible a formulaci√≥n | Tolerante a diferentes formas |
| **Resultados** | 1 consulta = N documentos | M consultas = N*M documentos (deduplicados) |

### Ejemplo Comparativo

```python
# B√∫squeda Simple
query = "resetear password"
docs = vectorstore.search(query)  # Solo busca esta frase exacta
# Resultado: 2 documentos

# MultiQuery
query = "resetear password"
variations = [
    "resetear password",
    "recuperar contrase√±a",
    "cambiar clave",
    "restablecer acceso"
]
all_docs = []
for q in variations:
    docs = vectorstore.search(q)
    all_docs.extend(docs)
# Resultado: 8 documentos √∫nicos (mejor cobertura)
```

---

## üíª Implementaci√≥n T√©cnica

### Estructura de la Clase

```python
class CustomMultiQueryRetriever(BaseRetriever):
    """
    Implementaci√≥n personalizada de MultiQueryRetriever.
    
    Atributos:
        retriever: Retriever base (e.g., ChromaDB retriever)
        llm: Modelo de lenguaje para generar variaciones
        prompt: Template para generaci√≥n de consultas
    """
    
    retriever: Any  # VectorStore retriever
    llm: Any        # ChatOpenAI
    prompt: Any     # ChatPromptTemplate
    
    class Config:
        arbitrary_types_allowed = True
```

### Flujo de Ejecuci√≥n

```mermaid
sequenceDiagram
    participant C as Cliente
    participant MQR as CustomMultiQueryRetriever
    participant LLM as GPT-4
    participant VDB as ChromaDB
    
    C->>MQR: invoke("¬øC√≥mo reseteo contrase√±a?")
    
    MQR->>MQR: _generate_queries()
    MQR->>LLM: Genera variaciones de la consulta
    LLM-->>MQR: ["reseteo contrase√±a", "recuperar password", ...]
    
    loop Para cada variaci√≥n
        MQR->>VDB: B√∫squeda sem√°ntica
        VDB-->>MQR: Documentos relevantes
    end
    
    MQR->>MQR: Eliminar duplicados
    MQR->>MQR: Ranking por relevancia
    MQR-->>C: Top-10 documentos √∫nicos
```

---

## üß† M√©todo: _generate_queries()

### C√≥digo Simplificado

```python
def _generate_queries(self, query: str) -> List[str]:
    """
    Genera m√∫ltiples versiones de la consulta original.
    
    Args:
        query: Consulta original del usuario
        
    Returns:
        Lista de 3-4 consultas (incluyendo la original)
    """
    try:
        # 1. Usar LLM para generar variaciones
        response = self.llm.invoke(self.prompt.format(question=query))
        queries_text = response.content.strip()
        
        # 2. Parsear respuesta
        queries = [query]  # Siempre incluir original
        
        for line in queries_text.split('\n'):
            line = line.strip()
            if line and line not in queries:
                # Limpiar formato (n√∫meros, guiones, etc.)
                cleaned = line.lstrip('0123456789.-) ')
                if cleaned and len(cleaned) > 10:
                    queries.append(cleaned)
        
        logging.info(f"Consultas generadas: {queries}")
        return queries[:4]  # M√°ximo 4 consultas
        
    except Exception as e:
        logging.warning(f"Error generando consultas: {e}")
        return [query]  # Fallback a consulta original
```

### Ejemplo de Prompt

```python
prompt = ChatPromptTemplate.from_template(
    """Eres un asistente de helpdesk experto. Tu tarea es generar m√∫ltiples 
versiones de la consulta del usuario para recuperar documentos relevantes de una 
base de conocimiento de soporte t√©cnico.

Genera 3 versiones diferentes de la consulta original, considerando:
- Sin√≥nimos t√©cnicos
- Diferentes formas de expresar el mismo problema
- Variaciones en terminolog√≠a de helpdesk

Consulta original: {question}

Versiones alternativas:"""
)
```

### Output Esperado

```
Input: "¬øC√≥mo reseteo mi contrase√±a?"

LLM Output:
1. Recuperar contrase√±a olvidada
2. Restablecer password de cuenta
3. Cambiar clave de acceso

Parsed Queries:
[
    "¬øC√≥mo reseteo mi contrase√±a?",  # Original
    "Recuperar contrase√±a olvidada",  # Variaci√≥n 1
    "Restablecer password de cuenta", # Variaci√≥n 2
    "Cambiar clave de acceso"         # Variaci√≥n 3
]
```

---

## üîÑ M√©todo: _get_relevant_documents()

### C√≥digo Simplificado

```python
def _get_relevant_documents(
    self, 
    query: str, 
    *, 
    run_manager: CallbackManagerForRetrieverRun = None
) -> List[Document]:
    """
    Recupera documentos relevantes usando m√∫ltiples consultas.
    
    Args:
        query: Consulta del usuario
        run_manager: Callback manager (opcional)
        
    Returns:
        Lista de documentos √∫nicos y relevantes
    """
    # 1. Generar consultas alternativas
    queries = self._generate_queries(query)
    
    # 2. Recuperar documentos para cada consulta
    all_docs = []
    seen_content = set()  # Para deduplicaci√≥n
    
    for q in queries:
        try:
            docs = self.retriever.invoke(q)
            
            for doc in docs:
                # Evitar duplicados por contenido
                if doc.page_content not in seen_content:
                    all_docs.append(doc)
                    seen_content.add(doc.page_content)
                    
        except Exception as e:
            logging.warning(f"Error recuperando docs para '{q}': {e}")
    
    # 3. Retornar top-10 m√°s relevantes
    return all_docs[:10]
```

---

## üìä Deduplicaci√≥n de Documentos

### Problema

```python
Query 1: "resetear contrase√±a"
Docs: [Doc A, Doc B, Doc C]

Query 2: "recuperar password"  
Docs: [Doc A, Doc D]  # Doc A es duplicado

Query 3: "cambiar clave"
Docs: [Doc B, Doc E]  # Doc B es duplicado

Total sin dedup: 7 documentos (con repetidos)
```

### Soluci√≥n

```python
seen_content = set()

for doc in all_docs:
    if doc.page_content not in seen_content:
        unique_docs.append(doc)
        seen_content.add(doc.page_content)

# Total con dedup: 5 documentos √∫nicos (A, B, C, D, E)
```

---

## üéØ Integraci√≥n con VectorRAGSystem

### C√≥digo de Inicializaci√≥n

```python
class VectorRAGSystem:
    def _load_vectorstore(self):
        # 1. Cargar ChromaDB
        self.vectorstore = Chroma(
            persist_directory=str(self.chroma_path),
            embedding_function=self.embeddings,
            collection_name="helpdesk_knowledge"
        )
        
        # 2. Crear retriever base
        base_retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 4}  # Top-4 por consulta
        )
        
        # 3. Envolver en CustomMultiQueryRetriever
        self.retriever = CustomMultiQueryRetriever(
            retriever=base_retriever,
            llm=self.llm,
            prompt=self._get_multi_query_prompt()
        )
```

### Uso en B√∫squeda

```python
def buscar(self, consulta: str) -> Dict[str, Any]:
    # CustomMultiQueryRetriever hace la magia internamente
    documentos = self.retriever.invoke(consulta)
    
    # Resto del procesamiento...
    contexto = self._generar_contexto(documentos)
    respuesta = self._generar_respuesta(consulta, contexto)
    confianza = self._calcular_confianza(consulta, documentos)
    
    return {
        "respuesta": respuesta,
        "confianza": confianza,
        "fuentes": [doc.metadata["filename"] for doc in documentos]
    }
```

---

## üìà M√©tricas de Mejora

### Antes (B√∫squeda Simple)

```python
Query: "resetear contrase√±a"
‚îú‚îÄ‚îÄ Documentos encontrados: 2
‚îú‚îÄ‚îÄ Confianza promedio: 0.65
‚îî‚îÄ‚îÄ Fuentes: 1
```

### Despu√©s (CustomMultiQueryRetriever)

```python
Query: "resetear contrase√±a"
‚îú‚îÄ‚îÄ Variaciones generadas: 4
‚îú‚îÄ‚îÄ Documentos encontrados: 5 (√∫nicos)
‚îú‚îÄ‚îÄ Confianza promedio: 0.85  # ‚Üë 30%
‚îî‚îÄ‚îÄ Fuentes: 3                 # ‚Üë 200%
```

---

## üß™ Testing del Retriever

### Test Unitario

```python
def test_custom_multi_query_retriever():
    # Setup
    retriever = CustomMultiQueryRetriever(
        retriever=mock_retriever,
        llm=mock_llm,
        prompt=test_prompt
    )
    
    # Test 1: Generaci√≥n de consultas
    queries = retriever._generate_queries("¬øC√≥mo reseteo password?")
    assert len(queries) >= 1
    assert len(queries) <= 4
    assert "¬øC√≥mo reseteo password?" in queries
    
    # Test 2: Recuperaci√≥n de documentos
    docs = retriever.invoke("¬øC√≥mo reseteo password?")
    assert isinstance(docs, list)
    assert all(isinstance(d, Document) for d in docs)
    
    # Test 3: Deduplicaci√≥n
    doc_contents = [d.page_content for d in docs]
    assert len(doc_contents) == len(set(doc_contents))
```

### Test de Integraci√≥n

```python
def test_rag_system_with_custom_retriever():
    # Setup completo del sistema
    rag = VectorRAGSystem(chroma_path="test_chroma_db")
    
    # Ejecutar b√∫squeda
    resultado = rag.buscar("¬øC√≥mo reseteo mi contrase√±a?")
    
    # Verificaciones
    assert "respuesta" in resultado
    assert resultado["confianza"] > 0.0
    assert len(resultado["fuentes"]) > 0
    
    # Verificar que us√≥ MultiQuery
    # (deber√≠a tener mejor confianza que b√∫squeda simple)
    assert resultado["confianza"] >= 0.6
```

---

## üîß Configuraci√≥n y Tuning

### Par√°metros Ajustables

```python
# 1. N√∫mero de variaciones
MAX_QUERIES = 4  # M√°s consultas = m√°s cobertura pero m√°s lento

# 2. Documentos por consulta
search_kwargs={"k": 4}  # Top-K por cada variaci√≥n

# 3. Total de documentos finales
return all_docs[:10]  # Top-10 globalmente

# 4. Longitud m√≠nima de consultas generadas
if cleaned and len(cleaned) > 10:  # Filtrar consultas muy cortas
```

### Optimizaci√≥n de Performance

```python
# Paralelizar b√∫squedas
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def _get_relevant_documents_async(self, query: str):
    queries = self._generate_queries(query)
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(self.retriever.invoke, q) 
            for q in queries
        ]
        results = [f.result() for f in futures]
    
    # Deduplicar y retornar
    return self._deduplicate(results)
```

---

## üêõ Troubleshooting

### Error: "Error generando consultas"

**Causa:** LLM no responde o formato inesperado

**Soluci√≥n:**
```python
# El c√≥digo ya maneja esto con fallback
return [query]  # Retorna consulta original
```

### Warning: "Error recuperando documentos para 'X'"

**Causa:** Una variaci√≥n de consulta fall√≥ en ChromaDB

**Soluci√≥n:** 
- El c√≥digo contin√∫a con otras consultas
- Al menos la consulta original siempre funciona

### Baja cantidad de documentos recuperados

**Ajustar par√°metros:**
```python
# Aumentar K por consulta
search_kwargs={"k": 6}  # De 4 a 6

# Aumentar total final
return all_docs[:15]  # De 10 a 15
```

---

## üìö Referencias

### LangChain Original (v0.1.x)
```python
# Versi√≥n antigua (no disponible en 1.0+)
from langchain.retrievers.multi_query import MultiQueryRetriever

retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(),
    llm=llm
)
```

### Nuestra Implementaci√≥n (Compatible 1.0+)
```python
# Versi√≥n personalizada (funcional en 1.0+)
from langchain_core.retrievers import BaseRetriever

class CustomMultiQueryRetriever(BaseRetriever):
    # ... implementaci√≥n completa
```

---

## üéì Lecciones Aprendidas

1. **Siempre tener fallbacks**: Si la generaci√≥n de consultas falla, usar la original
2. **Deduplicaci√≥n es cr√≠tica**: Evita documentos repetidos que bajan la calidad
3. **Logging es tu amigo**: Ayuda a debuggear qu√© consultas se generan
4. **Limitar resultados**: Top-10 es suficiente, m√°s puede degradar performance
5. **Validar inputs**: Filtrar consultas muy cortas o malformadas

---

## üöÄ Mejoras Futuras

### v1.1 - Cach√© de Consultas Generadas
```python
query_cache = {}

def _generate_queries_cached(self, query: str):
    if query in query_cache:
        return query_cache[query]
    
    queries = self._generate_queries(query)
    query_cache[query] = queries
    return queries
```

### v1.2 - Ranking con Scores
```python
def _get_relevant_documents(self, query):
    # ... b√∫squeda normal ...
    
    # Agregar scores de relevancia
    scored_docs = []
    for doc in all_docs:
        score = self._calculate_relevance(query, doc)
        scored_docs.append((doc, score))
    
    # Ordenar por score
    scored_docs.sort(key=lambda x: x[1], reverse=True)
    return [doc for doc, score in scored_docs[:10]]
```

### v1.3 - Embeddings H√≠bridos
```python
# Combinar b√∫squeda sem√°ntica + keyword
def hybrid_search(self, query):
    semantic_docs = self.semantic_search(query)
    keyword_docs = self.keyword_search(query)
    
    # Merge y re-rank
    return self._merge_results(semantic_docs, keyword_docs)
```

---

## ‚úÖ Checklist de Implementaci√≥n

Si quieres implementar tu propio CustomMultiQueryRetriever:

- [ ] Heredar de `BaseRetriever`
- [ ] Implementar `_get_relevant_documents()`
- [ ] Crear m√©todo `_generate_queries()` con LLM
- [ ] Agregar deduplicaci√≥n de documentos
- [ ] Incluir manejo de errores con fallbacks
- [ ] Agregar logging para debugging
- [ ] Limitar n√∫mero de consultas (3-4)
- [ ] Limitar documentos finales (10-15)
- [ ] Testear con casos reales
- [ ] Documentar par√°metros ajustables

---

**√öltima actualizaci√≥n:** Noviembre 2025  
**Versi√≥n:** 1.0  
**Autor:** Jose Balbuena  
**Estado:** ‚úÖ Producci√≥n - Funciona correctamente en LangChain 1.0+
