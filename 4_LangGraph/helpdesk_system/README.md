# ğŸ§ Sistema Helpdesk Inteligente con LangGraph y RAG

Sistema avanzado de atenciÃ³n al cliente que combina **LangGraph** para orquestaciÃ³n de flujos, **RAG (Retrieval-Augmented Generation)** para consultas a base de conocimiento, y **Human-in-the-Loop** para escalado inteligente a agentes humanos.

---

## ğŸ“‘ Tabla de Contenidos

1. [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
2. [Arquitectura del Sistema](#-arquitectura-del-sistema)
3. [Flujo de Trabajo Detallado](#-flujo-de-trabajo-detallado)
4. [Componentes del Sistema](#-componentes-del-sistema)
5. [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
6. [Uso del Sistema](#-uso-del-sistema)
7. [Estructura de Archivos](#-estructura-de-archivos)
8. [Ejemplos de Uso](#-ejemplos-de-uso)
9. [Troubleshooting](#-troubleshooting)

---

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¤– **ClasificaciÃ³n Inteligente**: Determina automÃ¡ticamente si una consulta puede resolverse con IA o requiere escalado humano
- ğŸ“š **Sistema RAG Avanzado**: BÃºsqueda semÃ¡ntica en base de conocimiento con ChromaDB
- ğŸ”„ **MultiQuery Personalizado**: Genera mÃºltiples versiones de consultas para mejorar la recuperaciÃ³n de informaciÃ³n
- ğŸ‘¤ **Human-in-the-Loop**: Escalado inteligente a agentes humanos con interrupciones controladas
- ğŸ’¾ **Persistencia con Checkpoints**: Mantiene estado de conversaciones usando SQLite
- ğŸ¨ **Interfaz Streamlit**: UI moderna y responsiva para usuarios y agentes
- ğŸ“Š **MÃ©tricas de Confianza**: Sistema de scoring para evaluar calidad de respuestas

---

## ğŸ—ï¸ Arquitectura del Sistema

### Diagrama General de Arquitectura

```mermaid
graph TB
    subgraph "Frontend"
        UI[Streamlit UI]
    end
    
    subgraph "LangGraph Orchestration"
        START([START])
        RAG[Procesar RAG]
        CLASSIFY[Clasificar con Contexto]
        AUTO[Respuesta AutomÃ¡tica]
        ESCALATE[Preparar Escalado]
        WAIT[Esperar Humano]
        HUMAN[Procesar Respuesta Humano]
        FINAL[Generar Respuesta Final]
        END([END])
    end
    
    subgraph "RAG System"
        VEC[(ChromaDB<br/>Vector Store)]
        EMB[OpenAI<br/>Embeddings]
        MQR[CustomMultiQuery<br/>Retriever]
    end
    
    subgraph "LLM Services"
        GPT[OpenAI GPT-4o-mini]
    end
    
    subgraph "Persistence"
        DB[(SQLite<br/>Checkpointer)]
    end
    
    UI -->|Consulta Usuario| START
    START --> RAG
    RAG --> MQR
    MQR --> VEC
    MQR --> GPT
    RAG --> CLASSIFY
    CLASSIFY -->|AutomÃ¡tico| AUTO
    CLASSIFY -->|Escalado| ESCALATE
    AUTO --> FINAL
    ESCALATE --> WAIT
    WAIT -->|InterrupciÃ³n| UI
    UI -->|Respuesta Agente| HUMAN
    HUMAN --> FINAL
    FINAL --> END
    END --> UI
    
    RAG -.-> DB
    CLASSIFY -.-> DB
    HUMAN -.-> DB
    
    style START fill:#90EE90
    style END fill:#FFB6C1
    style WAIT fill:#FFD700
    style RAG fill:#87CEEB
    style CLASSIFY fill:#DDA0DD
    style AUTO fill:#98FB98
    style ESCALATE fill:#FFA07A
```

### Diagrama de Flujo de Estados

```mermaid
stateDiagram-v2
    [*] --> ProcesarRAG: Nueva Consulta
    
    ProcesarRAG --> ClasificarConContexto: Contexto Recuperado
    
    ClasificarConContexto --> RespuestaAutomÃ¡tica: Confianza Alta<br/>(>0.6)
    ClasificarConContexto --> PrepararEscalado: Confianza Baja<br/>o Consulta Compleja
    
    RespuestaAutomÃ¡tica --> GenerarRespuestaFinal: Respuesta IA
    
    PrepararEscalado --> EsperarHumano: Requiere IntervenciÃ³n
    
    EsperarHumano --> ProcesarRespuestaHumano: Agente Responde
    EsperarHumano --> EsperarHumano: Sin Respuesta
    
    ProcesarRespuestaHumano --> GenerarRespuestaFinal: Respuesta Humana
    
    GenerarRespuestaFinal --> [*]: Ticket Resuelto
    
    note right of ProcesarRAG
        - BÃºsqueda semÃ¡ntica
        - MultiQuery para mejorar recall
        - CÃ¡lculo de confianza
    end note
    
    note right of ClasificarConContexto
        - AnÃ¡lisis de contexto RAG
        - EvaluaciÃ³n de confianza
        - DecisiÃ³n automÃ¡tica/escalado
    end note
    
    note right of EsperarHumano
        - Checkpoint de interrupciÃ³n
        - NotificaciÃ³n a agentes
        - Espera activa
    end note
```

---

## ğŸ”„ Flujo de Trabajo Detallado

### 1ï¸âƒ£ Fase: Procesar RAG

```mermaid
sequenceDiagram
    participant U as Usuario
    participant G as LangGraph
    participant MQ as MultiQueryRetriever
    participant LLM as GPT-4
    participant V as ChromaDB
    
    U->>G: Consulta: "Â¿CÃ³mo reinicio mi contraseÃ±a?"
    G->>MQ: Buscar contexto
    MQ->>LLM: Generar consultas alternativas
    LLM-->>MQ: ["Â¿CÃ³mo reinicio mi contraseÃ±a?",<br/>"Recuperar contraseÃ±a olvidada",<br/>"Resetear password de cuenta"]
    
    loop Para cada consulta
        MQ->>V: BÃºsqueda semÃ¡ntica
        V-->>MQ: Documentos relevantes
    end
    
    MQ->>MQ: Eliminar duplicados
    MQ->>MQ: Calcular confianza
    MQ-->>G: {respuesta, confianza, fuentes}
    G->>G: Actualizar estado
```

**Salida de esta fase:**
- `respuesta_rag`: Respuesta generada basada en documentos
- `confianza`: Score 0.0-1.0 basado en relevancia
- `fuentes`: Lista de documentos consultados
- `contexto_rag`: Contexto completo para siguiente fase

### 2ï¸âƒ£ Fase: ClasificaciÃ³n con Contexto

```mermaid
flowchart TD
    A[Estado con Contexto RAG] --> B{Analizar Consulta<br/>+ Contexto + Confianza}
    
    B -->|Confianza > 0.6<br/>InformaciÃ³n Completa| C[CategorÃ­a: AUTOMÃTICO]
    B -->|Confianza < 0.6<br/>o Consulta Compleja| D[CategorÃ­a: ESCALADO]
    
    C --> E[Generar Respuesta IA]
    D --> F[Preparar para Agente Humano]
    
    E --> G[Respuesta Final]
    F --> H[InterrupciÃ³n del Grafo]
    H --> I[Esperar IntervenciÃ³n]
    I --> J[Agente Proporciona Respuesta]
    J --> G
    
    style C fill:#90EE90
    style D fill:#FFA07A
    style H fill:#FFD700
```

**Criterios de ClasificaciÃ³n:**

| Criterio | AutomÃ¡tico âœ… | Escalado ğŸš¨ |
|----------|--------------|-------------|
| **Confianza RAG** | > 0.6 | < 0.6 |
| **Tipo de Consulta** | Procedimientos estÃ¡ndar | Casos Ãºnicos/complejos |
| **InformaciÃ³n Disponible** | Completa en BD | Insuficiente |
| **Requiere Acceso** | Solo informaciÃ³n pÃºblica | Sistemas internos |
| **DecisiÃ³n de Negocio** | No requerida | SÃ­ requerida |

### 3ï¸âƒ£ Fase: Human-in-the-Loop

```mermaid
sequenceDiagram
    participant G as LangGraph
    participant CP as Checkpointer
    participant UI as Streamlit UI
    participant A as Agente Humano
    
    G->>G: Determinar Escalado
    G->>CP: Guardar estado actual
    CP-->>G: Estado persistido
    G->>G: Alcanzar interrupt_before=["procesar_humano"]
    G-->>UI: Estado: ESPERANDO_HUMANO
    
    UI->>UI: Mostrar alerta a agentes
    UI->>UI: Mostrar contexto completo
    
    A->>UI: Revisar ticket
    A->>UI: Proporcionar respuesta
    UI->>G: Continuar con respuesta_humano
    G->>CP: Actualizar estado
    G->>G: Procesar respuesta humano
    G-->>UI: Ticket resuelto
```

---

## ğŸ§© Componentes del Sistema

### ğŸ“¦ 1. `rag_system.py` - Sistema RAG

**Clase Principal: `VectorRAGSystem`**

```python
VectorRAGSystem(chroma_path: str = "chroma_db")
```

**Componentes:**

#### `CustomMultiQueryRetriever`
ImplementaciÃ³n personalizada que reemplaza el `MultiQueryRetriever` de LangChain (no disponible en versiÃ³n 1.0+).

**Funcionamiento:**
1. **GeneraciÃ³n de Consultas**: Usa GPT para crear 3-4 variaciones de la consulta original
2. **RecuperaciÃ³n MÃºltiple**: Ejecuta bÃºsqueda semÃ¡ntica para cada variaciÃ³n
3. **DeduplicaciÃ³n**: Elimina documentos duplicados por contenido
4. **Ranking**: Retorna top-10 documentos mÃ¡s relevantes

```python
def _generate_queries(self, query: str) -> List[str]:
    """
    Input: "Â¿CÃ³mo reinicio mi contraseÃ±a?"
    Output: [
        "Â¿CÃ³mo reinicio mi contraseÃ±a?",
        "Recuperar contraseÃ±a olvidada",
        "Resetear password de cuenta",
        "Cambiar clave de acceso"
    ]
    """
```

#### CÃ¡lculo de Confianza

```python
def _calcular_confianza(self, consulta: str, documentos: List) -> float:
    """
    Factores considerados:
    - Coincidencias de palabras clave (peso: 60%)
    - NÃºmero de documentos relevantes (peso: 20%)
    - Longitud/calidad del contenido (peso: 20%)
    
    Returns: Score entre 0.0 y 1.0
    """
```

**Ejemplo de Scoring:**
- Consulta: "resetear contraseÃ±a"
- Documento contiene: "Para resetear tu contraseÃ±a, ve a configuraciÃ³n..."
- Coincidencias: 1/2 palabras â†’ Base: 0.5
- Documentos encontrados: 3 â†’ Bonus: +0.15
- Contenido: 500 palabras â†’ Bonus: +0.10
- **Confianza Final: 0.75** âœ…

---

### ğŸ”€ 2. `graph.py` - OrquestaciÃ³n LangGraph

**Clase Principal: `HelpdeskGraph`**

#### Estado del Sistema

```python
class HelpdeskState(TypedDict):
    consulta: str                      # Consulta original del usuario
    categoria: str                     # "automatico" | "escalado"
    respuesta_rag: Optional[str]       # Respuesta del sistema RAG
    confianza: float                   # Score de confianza (0.0-1.0)
    fuentes: List[str]                 # Documentos consultados
    contexto_rag: Optional[str]        # Contexto completo para clasificaciÃ³n
    requiere_humano: bool              # Flag de escalado
    respuesta_humano: Optional[str]    # Respuesta del agente
    respuesta_final: Optional[str]     # Respuesta final al usuario
    historial: List[str]               # Log de acciones
```

#### Nodos del Grafo

| Nodo | FunciÃ³n | Input | Output |
|------|---------|-------|--------|
| **procesar_rag** | BÃºsqueda en base de conocimiento | `consulta` | `respuesta_rag`, `confianza`, `fuentes` |
| **clasificar_con_contexto** | DecisiÃ³n automÃ¡tico/escalado | `consulta`, `contexto_rag`, `confianza` | `categoria` |
| **preparar_escalado** | Setup para intervenciÃ³n humana | Estado actual | `requiere_humano=True` |
| **procesar_humano** | Procesar respuesta del agente | `respuesta_humano` | `respuesta_final` |
| **generar_respuesta_final** | Formatear respuesta final | `respuesta_rag`/`respuesta_humano` | `respuesta_final` |

#### ConstrucciÃ³n del Grafo

```python
def crear_grafo(self):
    graph = StateGraph(HelpdeskState)
    
    # Agregar nodos
    graph.add_node("procesar_rag", self.procesar_rag)
    graph.add_node("clasificar_con_contexto", self.clasificar_con_contexto)
    graph.add_node("respuesta_final", self.generar_respuesta_final)
    graph.add_node("preparar_escalado", self.preparar_escalado)
    graph.add_node("procesar_humano", self.procesar_respuesta_humano)
    
    # Flujo principal
    graph.add_edge(START, "procesar_rag")
    graph.add_edge("procesar_rag", "clasificar_con_contexto")
    
    # Branching condicional
    graph.add_conditional_edges(
        "clasificar_con_contexto",
        lambda state: state["categoria"],
        {
            "automatico": "respuesta_final",
            "escalado": "preparar_escalado"
        }
    )
    
    # Flujo de escalado con interrupciÃ³n
    graph.add_conditional_edges(
        "preparar_escalado",
        lambda state: "esperar" if state["requiere_humano"] else "procesar_humano",
        {
            "procesar_humano": "procesar_humano",
            "esperar": END  # âš¡ Checkpoint de interrupciÃ³n
        }
    )
    
    return graph
```

---

### ğŸ¨ 3. `app.py` - Interfaz Streamlit

**Arquitectura de la Interfaz:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HELPDESK 2.0 CON RAG                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š PANEL DE CONTROL                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Total Tickets  â”‚ AutomÃ¡ticos    â”‚ Escalados        â”‚ â”‚
â”‚  â”‚      ğŸ«        â”‚    âœ…          â”‚    â³            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ†• CREAR NUEVO TICKET                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ [Campo de texto para consulta]                    â”‚  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚ [BotÃ³n: Enviar Consulta]                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‹ TICKETS ACTIVOS                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ TK-A3F2E1                              âœ… Resuelto â”‚  â”‚
â”‚  â”‚ "Â¿CÃ³mo reinicio mi contraseÃ±a?"                   â”‚  â”‚
â”‚  â”‚ Confianza: 0.85 | Fuentes: manual_usuario.md     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ TK-B8D4C7                        â³ Esperando Agentâ”‚  â”‚
â”‚  â”‚ "Problema con facturaciÃ³n"                        â”‚  â”‚
â”‚  â”‚ Confianza: 0.45 | Escalado automÃ¡tico            â”‚  â”‚
â”‚  â”‚ [Campo: Respuesta Agente] [BotÃ³n: Responder]     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Funciones Principales:**

#### `procesar_consulta(consulta: str, ticket_id: str)`
```python
def procesar_consulta(consulta: str, ticket_id: str):
    """
    1. Crear estado inicial con consulta
    2. Ejecutar grafo con thread_id Ãºnico
    3. Capturar interrupciÃ³n si requiere humano
    4. Retornar estado final
    """
    config = {"configurable": {"thread_id": ticket_id}}
    estado_final = st.session_state.helpdesk.invoke(estado_inicial, config)
    return estado_final
```

#### `continuar_con_respuesta_humano(ticket_id: str, respuesta: str)`
```python
def continuar_con_respuesta_humano(ticket_id: str, respuesta: str):
    """
    1. Recuperar checkpoint con thread_id
    2. Actualizar estado con respuesta_humano
    3. Continuar ejecuciÃ³n del grafo
    4. Retornar estado resuelto
    """
    estado = st.session_state.helpdesk.get_state(config)
    estado_actualizado = {**estado.values, "respuesta_humano": respuesta}
    estado_final = st.session_state.helpdesk.invoke(estado_actualizado, config)
    return estado_final
```

---

### âš™ï¸ 4. `setup_rag.py` - ConfiguraciÃ³n RAG

**Clase: `DocumentProcessor`**

```python
def setup_rag_system(self, force_rebuild: bool = False):
    """
    Pipeline de procesamiento:
    
    1. Cargar documentos (.md, .txt, .pdf)
       â†“
    2. Text Splitting (chunks de 500 chars, overlap 100)
       â†“
    3. Generar embeddings (OpenAI text-embedding-3-large)
       â†“
    4. Almacenar en ChromaDB
       â†“
    5. Retornar vectorstore
    """
```

**ConfiguraciÃ³n de Chunks:**
```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,        # TamaÃ±o Ã³ptimo para contexto
    chunk_overlap=100,     # Mantiene continuidad
    length_function=len,
    separators=["\n\n", "\n", " ", ""]  # Prioridad de splits
)
```

---

### ğŸ“„ 5. `config.py` - ConfiguraciÃ³n Global

```python
# Rutas del sistema
CHROMADB_PATH = ".../chroma_db"
DOCS_PATH = ".../docs"

# Modelos
EMBEDDINGS_MODEL = "text-embedding-3-large"  # 3072 dimensiones
LLM_MODEL = "gpt-4o-mini"                     # ClasificaciÃ³n y generaciÃ³n

# ParÃ¡metros RAG
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100
TOP_K_DOCS = 4

# Umbrales
CONFIDENCE_THRESHOLD = 0.6  # MÃ­nimo para respuesta automÃ¡tica
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.11+
- Conda (recomendado)
- Cuenta OpenAI con API key

### Paso 1: Crear Entorno

```bash
conda create -n llms python=3.11
conda activate llms
```

### Paso 2: Instalar Dependencias

```bash
pip install langchain==1.0.3
pip install langchain-community==0.4.1
pip install langchain-core==1.0.3
pip install langchain-openai==1.0.2
pip install langchain-chroma==0.2.6
pip install langgraph==1.0.2
pip install langgraph-checkpoint==3.0.1
pip install langgraph-checkpoint-sqlite==3.0.0
pip install streamlit
pip install python-dotenv
```

### Paso 3: Configurar Variables de Entorno

```bash
# Crear archivo .env
echo "OPENAI_API_KEY=tu-api-key-aqui" > .env
```

### Paso 4: Preparar Documentos

```bash
# Crear estructura de carpetas
mkdir -p docs
mkdir -p chroma_db

# Agregar documentos a docs/
# Formatos soportados: .md, .txt, .pdf
```

### Paso 5: Inicializar Sistema RAG

```bash
# OpciÃ³n 1: Desde la interfaz Streamlit
streamlit run app.py
# Click en "Configurar Sistema RAG"

# OpciÃ³n 2: Script manual
python setup_rag.py
```

### Paso 6: Ejecutar AplicaciÃ³n

```bash
conda activate llms
streamlit run app.py
```

Acceder a: http://localhost:8502

---

## ğŸ’¡ Uso del Sistema

### Escenario 1: Consulta AutomÃ¡tica âœ…

**Entrada:**
```
Usuario: "Â¿CÃ³mo reinicio mi contraseÃ±a?"
```

**Proceso Interno:**
1. **RAG**: Busca en base de conocimiento
   - Consultas generadas: ["Â¿CÃ³mo reinicio mi contraseÃ±a?", "Recuperar contraseÃ±a", "Resetear password"]
   - Documentos encontrados: 3 (manual_usuario.md, faq.md)
   - Confianza: 0.85

2. **ClasificaciÃ³n**: AnÃ¡lisis con contexto
   - InformaciÃ³n completa: âœ…
   - Confianza alta: âœ…
   - CategorÃ­a: **AUTOMÃTICO**

3. **Respuesta Final**:
```
Para reiniciar tu contraseÃ±a:

1. Ve a la pÃ¡gina de inicio de sesiÃ³n
2. Haz clic en "Â¿Olvidaste tu contraseÃ±a?"
3. Ingresa tu correo electrÃ³nico
4. Revisa tu bandeja de entrada
5. Sigue el enlace de recuperaciÃ³n

Fuentes consultadas: manual_usuario.md, faq.md
```

**Estado del Ticket:**
- âœ… Resuelto AutomÃ¡ticamente
- â±ï¸ Tiempo: <5 segundos
- ğŸ¤– Agente: IA

---

### Escenario 2: Escalado a Humano ğŸš¨

**Entrada:**
```
Usuario: "Tengo un problema con mi factura del mes pasado, 
me cobraron doble"
```

**Proceso Interno:**
1. **RAG**: Busca informaciÃ³n
   - Documentos: 1 (guia_facturacion.md - info general)
   - Confianza: 0.35

2. **ClasificaciÃ³n**:
   - InformaciÃ³n insuficiente: âŒ
   - Requiere acceso a sistemas: âœ…
   - Caso especÃ­fico: âœ…
   - CategorÃ­a: **ESCALADO**

3. **InterrupciÃ³n**: Checkpointer guarda estado
   ```python
   {
       "consulta": "...",
       "contexto_rag": "...",
       "requiere_humano": True,
       "estado": "ESPERANDO_AGENTE"
   }
   ```

4. **NotificaciÃ³n UI**: 
   - ğŸ”” Alerta a agentes
   - ğŸ“‹ Muestra contexto completo
   - â³ Ticket en espera

5. **Agente Responde:**
```
Hola, revisÃ© tu cuenta y efectivamente hubo un error 
en la facturaciÃ³n. He procesado el reembolso que verÃ¡s 
reflejado en 3-5 dÃ­as hÃ¡biles. Disculpa las molestias.
```

6. **ContinuaciÃ³n del Grafo:**
   - Estado actualizado con respuesta_humano
   - Procesa respuesta
   - Genera respuesta final
   - âœ… Ticket resuelto

**Estado del Ticket:**
- âœ… Resuelto por Humano
- â±ï¸ Tiempo: 5 minutos
- ğŸ‘¤ Agente: MarÃ­a GonzÃ¡lez

---

## ğŸ“Š Estructura de Archivos

```
helpdesk_system/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                      # Interfaz Streamlit principal
â”œâ”€â”€ ğŸ“„ graph.py                    # DefiniciÃ³n del grafo LangGraph
â”œâ”€â”€ ğŸ“„ rag_system.py               # Sistema RAG con CustomMultiQueryRetriever
â”œâ”€â”€ ğŸ“„ setup_rag.py                # InicializaciÃ³n de vectorstore
â”œâ”€â”€ ğŸ“„ config.py                   # ConfiguraciÃ³n global
â”œâ”€â”€ ğŸ“„ README.md                   # Esta documentaciÃ³n
â”œâ”€â”€ ğŸ“„ .env                        # Variables de entorno (API keys)
â”œâ”€â”€ ğŸ“„ helpdesk.db                 # Base de datos SQLite para checkpoints
â”‚
â”œâ”€â”€ ğŸ“ docs/                       # Documentos de conocimiento
â”‚   â”œâ”€â”€ manual_usuario.md
â”‚   â”œâ”€â”€ faq.md
â”‚   â””â”€â”€ guia_resolucion_problemas.md
â”‚
â”œâ”€â”€ ğŸ“ chroma_db/                  # Base de datos vectorial
â”‚   â”œâ”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ [colecciones de embeddings]
â”‚
â””â”€â”€ ğŸ“ __pycache__/                # Archivos Python compilados
```

---

## ğŸ” Ejemplos de Uso

### Ejemplo 1: Ejecutar Consulta ProgramÃ¡ticamente

```python
from graph import crear_helpdesk, HelpdeskState

# Inicializar sistema
helpdesk = crear_helpdesk()

# Crear estado inicial
estado = HelpdeskState(
    consulta="Â¿CuÃ¡l es el horario de atenciÃ³n?",
    categoria="",
    respuesta_rag=None,
    confianza=0.0,
    fuentes=[],
    contexto_rag=None,
    requiere_humano=False,
    respuesta_humano=None,
    respuesta_final=None,
    historial=[]
)

# Ejecutar grafo
config = {"configurable": {"thread_id": "ticket-123"}}
resultado = helpdesk.invoke(estado, config)

# Ver respuesta
print(resultado["respuesta_final"])
print(f"Confianza: {resultado['confianza']}")
print(f"Requiere humano: {resultado['requiere_humano']}")
```

### Ejemplo 2: Procesar Escalado

```python
# Primera parte: ejecutar hasta interrupciÃ³n
resultado = helpdesk.invoke(estado, config)

if resultado["requiere_humano"]:
    # Simular respuesta de agente
    estado_actualizado = {
        **resultado,
        "respuesta_humano": "AquÃ­ estÃ¡ la soluciÃ³n a tu problema..."
    }
    
    # Continuar desde checkpoint
    resultado_final = helpdesk.invoke(estado_actualizado, config)
    print(resultado_final["respuesta_final"])
```

### Ejemplo 3: Consultar Estado de Checkpoint

```python
# Obtener estado actual
config = {"configurable": {"thread_id": "ticket-123"}}
checkpoint = helpdesk.get_state(config)

print(f"Valores: {checkpoint.values}")
print(f"Siguiente nodo: {checkpoint.next}")
print(f"Metadata: {checkpoint.config}")
```

---

## ğŸ› Troubleshooting

### Error: `ModuleNotFoundError: No module named 'langchain.retrievers'`

**Causa:** LangChain 1.0+ reorganizÃ³ mÃ³dulos y `MultiQueryRetriever` no estÃ¡ disponible directamente.

**SoluciÃ³n:** âœ… Ya implementado
- Sistema usa `CustomMultiQueryRetriever` personalizado
- Funcionalidad idÃ©ntica al original
- No requiere cambios adicionales

---

### Error: `ModuleNotFoundError: No module named 'langgraph.checkpoint.sqlite'`

**Causa:** Falta el paquete de checkpoints SQLite.

**SoluciÃ³n:**
```bash
conda activate llms
pip install langgraph-checkpoint-sqlite==3.0.0
```

---

### Error: `ChromaDB no encontrado`

**Causa:** No se ha inicializado la base de datos vectorial.

**SoluciÃ³n:**
1. Desde Streamlit: Click en "âš™ï¸ Configurar Sistema RAG"
2. Desde terminal:
```bash
python setup_rag.py
```

---

### Error: `OpenAI API Key no vÃ¡lida`

**Causa:** Variable de entorno no configurada o API key incorrecta.

**SoluciÃ³n:**
```bash
# Verificar .env
cat .env

# Debe contener:
# OPENAI_API_KEY=sk-...

# Si no existe, crear:
echo "OPENAI_API_KEY=tu-key-aqui" > .env
```

---

### Tickets Atascados en "Esperando Humano"

**Causa:** Estado no se actualiza despuÃ©s de respuesta de agente.

**SoluciÃ³n:**
1. Verificar que `thread_id` sea consistente
2. Usar botÃ³n "âœ… Responder Ticket" en UI
3. No recargar pÃ¡gina durante procesamiento

**Debug:**
```python
# Ver estado actual
checkpoint = helpdesk.get_state(config)
print(checkpoint.values["requiere_humano"])
print(checkpoint.next)  # Debe ser ["procesar_humano"]
```

---

### Confianza Siempre Baja

**Causa:** Documentos en base de conocimiento no relevantes o mal fragmentados.

**SoluciÃ³n:**
1. Revisar documentos en `docs/`
2. Ajustar chunk_size en `setup_rag.py`:
```python
chunk_size=500  # Aumentar a 800 si es necesario
chunk_overlap=100  # Aumentar a 150
```
3. Reconstruir vectorstore:
```bash
python setup_rag.py --force-rebuild
```

---

## ğŸ“ˆ MÃ©tricas y Monitoreo

### Logs del Sistema

```python
import logging

# Activar logs detallados
logging.basicConfig(level=logging.INFO)
logging.getLogger("langchain.retrievers").setLevel(logging.DEBUG)
```

**Output esperado:**
```
INFO:langchain.retrievers:Consultas generadas: [
    "Â¿CÃ³mo reinicio mi contraseÃ±a?",
    "Recuperar contraseÃ±a olvidada",
    "Resetear password"
]
INFO:langchain.retrievers:Documentos recuperados: 3
INFO:graph:Confianza calculada: 0.85
INFO:graph:ClasificaciÃ³n: automatico
```

---

## ğŸ¯ Mejores PrÃ¡cticas

### 1. OrganizaciÃ³n de Documentos

```markdown
docs/
â”œâ”€â”€ 01_manual_usuario.md       # Procedimientos paso a paso
â”œâ”€â”€ 02_faq.md                  # Preguntas frecuentes
â”œâ”€â”€ 03_troubleshooting.md      # ResoluciÃ³n de problemas
â”œâ”€â”€ 04_politicas.md            # PolÃ­ticas de la empresa
â””â”€â”€ 05_api_docs.md             # DocumentaciÃ³n tÃ©cnica
```

**Formato recomendado para documentos:**
```markdown
# TÃ­tulo de la SecciÃ³n

## Pregunta: Â¿CÃ³mo hacer X?

**Respuesta:**
1. Paso 1
2. Paso 2
3. Paso 3

**Nota importante:** InformaciÃ³n adicional

---
```

### 2. OptimizaciÃ³n de Confianza

- âœ… Documentos bien estructurados
- âœ… InformaciÃ³n clara y directa
- âœ… Vocabulario consistente
- âœ… Ejemplos concretos
- âŒ Textos ambiguos
- âŒ InformaciÃ³n desactualizada

### 3. GestiÃ³n de Escalados

**Buenas prÃ¡cticas:**
- Proporcionar contexto completo al agente
- Incluir historial de consulta
- Documentar resoluciÃ³n para futura referencia
- Actualizar base de conocimiento con casos nuevos

---

## ğŸ”’ Seguridad y Privacidad

### Manejo de Datos Sensibles

```python
# NO incluir en documentos:
- ContraseÃ±as
- NÃºmeros de tarjetas de crÃ©dito
- InformaciÃ³n personal identificable (PII)
- Tokens de API

# SÃ incluir:
- Procedimientos generales
- Pasos de troubleshooting
- PolÃ­ticas pÃºblicas
```

### SanitizaciÃ³n de Logs

```python
# En producciÃ³n, sanitizar logs
import re

def sanitize_log(text: str) -> str:
    # Remover emails
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', text)
    # Remover nÃºmeros de telÃ©fono
    text = re.sub(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', '[PHONE]', text)
    return text
```

---

## ğŸš€ Roadmap Futuro

### PrÃ³ximas CaracterÃ­sticas

- [ ] **AnÃ¡lisis de Sentimiento**: PriorizaciÃ³n de tickets por urgencia emocional
- [ ] **Multi-idioma**: Soporte para espaÃ±ol, inglÃ©s, portuguÃ©s
- [ ] **IntegraciÃ³n con Slack/Teams**: Notificaciones en tiempo real
- [ ] **Dashboard de Analytics**: MÃ©tricas de rendimiento y KPIs
- [ ] **A/B Testing**: OptimizaciÃ³n continua de respuestas
- [ ] **Fine-tuning**: Modelo personalizado para dominio especÃ­fico

---

## ğŸ“ Soporte y Contribuciones

### Reportar Bugs

```markdown
**DescripciÃ³n del problema:**
[DescripciÃ³n clara y concisa]

**Pasos para reproducir:**
1. ...
2. ...

**Comportamiento esperado:**
[QuÃ© deberÃ­a suceder]

**Logs relevantes:**
[Copiar logs aquÃ­]

**Entorno:**
- Python: 3.11
- LangChain: 1.0.3
- OS: Ubuntu 22.04
```

### Contribuir

1. Fork el repositorio
2. Crear branch de feature: `git checkout -b feature/nueva-caracteristica`
3. Commit cambios: `git commit -m 'Agregar nueva caracterÃ­stica'`
4. Push a branch: `git push origin feature/nueva-caracteristica`
5. Crear Pull Request

---

## ğŸ“š Referencias y Recursos

### DocumentaciÃ³n Oficial

- [LangChain](https://python.langchain.com/)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [ChromaDB](https://docs.trychroma.com/)
- [Streamlit](https://docs.streamlit.io/)
- [OpenAI API](https://platform.openai.com/docs/)

### Tutoriales Relacionados

- [LangGraph Human-in-the-Loop](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)
- [RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/)
- [Vector Stores Guide](https://python.langchain.com/docs/integrations/vectorstores/)

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¥ Autores

**Jose Balbuena**
- GitHub: [@JoseBalbuena181096](https://github.com/JoseBalbuena181096)
- Proyecto: IngenierÃ­a de LLM - LangChain, LangGraph y Agentes AI con Python

---

## ğŸ™ Agradecimientos

- Equipo de LangChain por el framework increÃ­ble
- Comunidad de desarrolladores de IA
- Colaboradores y testers

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025  
**VersiÃ³n:** 2.0  
**Estado:** âœ… ProducciÃ³n
