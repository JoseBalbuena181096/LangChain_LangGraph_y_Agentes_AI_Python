# ğŸ¤– Chat Multi-Usuario con Memoria Avanzada

Este proyecto implementa un sistema de chat inteligente capaz de manejar mÃºltiples usuarios, mantener el contexto de las conversaciones y gestionar una memoria a largo plazo utilizando bases de datos vectoriales. EstÃ¡ construido con **Python**, **Streamlit**, **LangChain** y **LangGraph**.

## ğŸ“‹ DescripciÃ³n General

El sistema permite a los usuarios tener conversaciones naturales con un asistente de IA que "recuerda" detalles importantes de charlas anteriores. A diferencia de los chatbots tradicionales que pierden el contexto al cerrar la sesiÃ³n o superar el lÃ­mite de tokens, este sistema utiliza una arquitectura hÃ­brida de memoria:

1.  **Memoria a Corto Plazo (LangGraph)**: Mantiene el hilo de la conversaciÃ³n actual.
2.  **Memoria a Largo Plazo (ChromaDB)**: Almacena hechos importantes, preferencias y datos personales de forma permanente.

### CaracterÃ­sticas Principales

*   **ğŸ‘¥ Multi-Usuario**: Soporte para mÃºltiples perfiles de usuario independientes.
*   **ğŸ’¾ Persistencia**: Historial de chats guardado y recuperable.
*   **ğŸ§  Memoria Vectorial**: ExtracciÃ³n y recuperaciÃ³n automÃ¡tica de informaciÃ³n relevante.
*   **âš¡ OptimizaciÃ³n de Contexto**: GestiÃ³n inteligente de tokens para conversaciones largas.
*   **ğŸ¨ Interfaz Moderna**: UI intuitiva construida con Streamlit.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

*   **[Streamlit](https://streamlit.io/)**: Framework para la interfaz de usuario.
*   **[LangChain](https://www.langchain.com/)**: OrquestaciÃ³n de LLMs y herramientas.
*   **[LangGraph](https://langchain-ai.github.io/langgraph/)**: GestiÃ³n del flujo de conversaciÃ³n y estado.
*   **[ChromaDB](https://www.trychroma.com/)**: Base de datos vectorial para la memoria semÃ¡ntica.
*   **[OpenAI](https://openai.com/)**: Modelos de lenguaje (GPT-4o/GPT-5-nano).
*   **SQLite**: Almacenamiento de checkpoints de estado.

## ğŸ—ï¸ Arquitectura del Sistema

### Flujo de Datos General

```mermaid
graph TD
    User[ğŸ‘¤ Usuario] <--> UI[ğŸ’» Interfaz Streamlit]
    UI <--> Manager[ğŸ”§ Chatbot Manager]
    Manager <--> LG[ğŸ”„ LangGraph Workflow]
    
    subgraph "Sistema de Memoria"
        LG <--> MEM[ğŸ§  Memory Manager]
        MEM <--> VDB[(ğŸ—„ï¸ ChromaDB\nMemoria Vectorial)]
        MEM <--> SQL[(ğŸ’¾ SQLite\nEstado ConversaciÃ³n)]
        MEM <--> META[(ğŸ“„ JSON\nMetadatos Chats)]
    end
    
    LG <--> LLM[ğŸ¤– OpenAI LLM]
```

### Flujo de Procesamiento del Chat (LangGraph)

El nÃºcleo del chatbot utiliza un grafo de estados para procesar cada mensaje:

```mermaid
stateDiagram-v2
    [*] --> RecuperacionMemoria: ğŸ“¨ Mensaje Usuario
    
    state RecuperacionMemoria {
        [*] --> BuscarVDB: Query Vectorial
        BuscarVDB --> Contexto: Memorias Relevantes
    }
    
    RecuperacionMemoria --> OptimizacionContexto: Contexto + Historial
    
    state OptimizacionContexto {
        [*] --> Trimming: Recortar Mensajes Antiguos
        Trimming --> Prompt: Contexto Optimizado
    }
    
    OptimizacionContexto --> GeneracionRespuesta: Prompt Final
    
    state GeneracionRespuesta {
        [*] --> LLM: Invocar Modelo
        LLM --> Respuesta: Texto Generado
    }
    
    GeneracionRespuesta --> ExtraccionMemoria: Respuesta Asistente
    
    state ExtraccionMemoria {
        [*] --> Analisis: Â¿Hay info nueva?
        Analisis --> Guardar: Si (CategorÃ­a/Importancia)
        Analisis --> Ignorar: No
        Guardar --> VDB: Insertar Vector
    }
    
    ExtraccionMemoria --> [*]: ğŸ Fin Turno
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

*   Python 3.9+
*   Una API Key de OpenAI

### Pasos

1.  **Clonar el repositorio**
    ```bash
    git clone <url-del-repositorio>
    cd multiuser_chat_system
    ```

2.  **Instalar dependencias**
    Crea un archivo `requirements.txt` con el siguiente contenido o instÃ¡lalos directamente:
    ```text
    streamlit
    langchain
    langgraph
    langchain-openai
    langchain-chroma
    chromadb
    python-dotenv
    pydantic
    ```
    
    InstalaciÃ³n:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Configurar variables de entorno**
    Crea un archivo `.env` en la raÃ­z del proyecto:
    ```env
    OPENAI_API_KEY=sk-tu-api-key-aqui
    ```

4.  **Ejecutar la aplicaciÃ³n**
    ```bash
    streamlit run app.py
    ```

## ğŸ“‚ Estructura del Proyecto

*   `app.py`: Punto de entrada de la aplicaciÃ³n Streamlit. Maneja la UI y la gestiÃ³n de sesiones.
*   `chatbot.py`: Define la lÃ³gica del chatbot usando `LangGraph`. Contiene el grafo de estados y la configuraciÃ³n del LLM.
*   `memory_manager.py`: Gestiona todas las operaciones de memoria (vectorial y persistencia de archivos). Incluye la lÃ³gica de extracciÃ³n automÃ¡tica de informaciÃ³n.
*   `config.py`: Archivo de configuraciÃ³n central (rutas, modelos, constantes).
*   `utils.py`: Funciones auxiliares para formateo y validaciÃ³n.
*   `users/`: Directorio donde se almacenan los datos persistentes de cada usuario (DBs, Ã­ndices vectoriales).

## ğŸ’¡ CÃ³mo Funciona la Memoria

El sistema utiliza un enfoque proactivo para la memoria:

1.  **ExtracciÃ³n**: Cada vez que el usuario envÃ­a un mensaje, un modelo secundario analiza si contiene informaciÃ³n digna de recordar (ej. "Me llamo Juan", "Soy ingeniero", "No me gusta el picante").
2.  **CategorizaciÃ³n**: La informaciÃ³n se clasifica en categorÃ­as (Personal, Profesional, Preferencias, Hechos Importantes) y se le asigna un nivel de importancia.
3.  **Almacenamiento**: Se convierte en un vector (embedding) y se guarda en ChromaDB.
4.  **RecuperaciÃ³n**: Cuando el usuario habla de nuevo, el sistema busca semÃ¡nticamente en la base de datos vectorial para encontrar recuerdos relevantes y los inyecta en el contexto del LLM.

---
Desarrollado para el curso de IngenierÃ­a de LLM y Agentes AI.
